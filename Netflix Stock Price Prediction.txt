Netflix Stock Price Prediction

(Using LSTM neural network)


IN[]:
import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta

# Get today's date
today = datetime.today()

# Format today's date
end_date = today.strftime("%Y-%m-%d")

# Calculate start date (5000 days ago)
start_date = today - timedelta(days=5000)
start_date = start_date.strftime("%Y-%m-%d")

# Download stock data for Netflix (NFLX)
data = yf.download('NFLX', 
                   start=start_date, 
                   end=end_date, 
                   progress=False)

# Extracting relevant columns and resetting index
data.reset_index(inplace=True)
data = data[["Date", "Open", "High", "Low", "Close", "Adj Close", "Volume"]]

# Display the tail of the dataframe
print(data.tail().to_string(index=False))

OUT[]:
 Date       Open       High        Low      Close  Adj Close  Volume
2024-03-22 624.159973 629.049988 621.000000 628.010010 628.010010 2134100
2024-03-25 627.900024 630.460022 623.159973 627.460022 627.460022 1803300
2024-03-26 625.200012 634.390015 619.179993 629.239990 629.239990 2804500
2024-03-27 629.010010 631.349976 610.729980 613.530029 613.530029 2628300
2024-03-28 614.989990 615.000000 601.590027 607.330017 607.330017 3706700


IN[]:
pip install mplfinance

OUT[]:
Requirement already satisfied: mplfinance in /usr/local/lib/python3.10/dist-packages (0.12.10b0)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mplfinance) (3.7.1)
Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mplfinance) (1.5.3)
Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.2.0)
Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (4.50.0)
Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.4.5)
Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (1.25.2)
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (24.0)
Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (9.4.0)
Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (3.1.2)
Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mplfinance) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mplfinance) (2023.4)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mplfinance) (1.16.0)


IN[]:
import yfinance as yf
import mplfinance as mpf

# Download stock data for Netflix (NFLX)
data = yf.download('NFLX', 
                   start='2020-01-01', 
                   end='2022-01-01', 
                   progress=False)

# Plot candlestick chart
mpf.plot(data, type='candle', volume=True, style='yahoo', title='Netflix Stock Price')

OUT[]:
// GRAPH

IN[]:
import pandas as pd
import yfinance as yf

# Download stock data for Netflix (NFLX)
data = yf.download('NFLX', 
                   start='2020-01-01', 
                   end='2022-01-01', 
                   progress=False)

# Calculate correlations
correlation = data.corrwith(data['Close'])

# Print correlations
print("Correlation with Close column:")
print(correlation)

OUT[]:
Correlation with Close column:
Open         0.993232
High         0.996861
Low          0.996918
Close        1.000000
Adj Close    1.000000
Volume      -0.347928
dtype: float64

IN[[]:
x = data[["Open", "High", "Low", "Volume"]]
y = data["Close"]
x = x.to_numpy()
y = y.to_numpy()
y = y.reshape(-1, 1)

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x, y, 
                                                test_size=0.2, 
                                                random_state=42)
from keras.models import Sequential
from keras.layers import Dense, LSTM
model = Sequential()
model.add(LSTM(128, return_sequences=True, input_shape= (xtrain.shape[1], 1)))
model.add(LSTM(64, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))
model.summary()

OUT[]:
Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm_2 (LSTM)               (None, 4, 128)            66560     
                                                                 
 lstm_3 (LSTM)               (None, 64)                49408     
                                                                 
 dense_4 (Dense)             (None, 25)                1625      
                                                                 
 dense_5 (Dense)             (None, 1)                 26        
                                                                 
=================================================================
Total params: 117619 (459.45 KB)
Trainable params: 117619 (459.45 KB)
Non-trainable params: 0 (0.00 Byte)

IN[]:
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(xtrain, ytrain, batch_size=1, epochs=30)

OUT[]:
Epoch 1/30
404/404 [==============================] - 8s 10ms/step - loss: 109782.5859
Epoch 2/30
404/404 [==============================] - 3s 7ms/step - loss: 6887.3311
Epoch 3/30
404/404 [==============================] - 3s 7ms/step - loss: 6727.7500
Epoch 4/30
404/404 [==============================] - 3s 8ms/step - loss: 6664.7148
Epoch 5/30
404/404 [==============================] - 4s 10ms/step - loss: 6771.4697
Epoch 6/30
404/404 [==============================] - 3s 7ms/step - loss: 6686.8130
Epoch 7/30
404/404 [==============================] - 3s 7ms/step - loss: 6685.4614
Epoch 8/30
404/404 [==============================] - 3s 7ms/step - loss: 6287.0361
Epoch 9/30
404/404 [==============================] - 4s 10ms/step - loss: 1494.0687
Epoch 10/30
404/404 [==============================] - 3s 8ms/step - loss: 553.6365
Epoch 11/30
404/404 [==============================] - 3s 8ms/step - loss: 432.6432
Epoch 12/30
404/404 [==============================] - 3s 8ms/step - loss: 212.6358
Epoch 13/30
404/404 [==============================] - 4s 9ms/step - loss: 337.5998
Epoch 14/30
404/404 [==============================] - 3s 8ms/step - loss: 453.0030
Epoch 15/30
404/404 [==============================] - 4s 9ms/step - loss: 354.8208
Epoch 16/30
404/404 [==============================] - 5s 11ms/step - loss: 363.9971
Epoch 17/30
404/404 [==============================] - 3s 8ms/step - loss: 220.9916
Epoch 18/30
404/404 [==============================] - 4s 11ms/step - loss: 180.9536
Epoch 19/30
404/404 [==============================] - 4s 11ms/step - loss: 286.0664
Epoch 20/30
404/404 [==============================] - 3s 8ms/step - loss: 270.8610
Epoch 21/30
404/404 [==============================] - 3s 8ms/step - loss: 227.0129
Epoch 22/30
404/404 [==============================] - 3s 8ms/step - loss: 516.1630
Epoch 23/30
404/404 [==============================] - 4s 10ms/step - loss: 158.5440
Epoch 24/30
404/404 [==============================] - 3s 7ms/step - loss: 179.4260
Epoch 25/30
404/404 [==============================] - 3s 7ms/step - loss: 331.6429
Epoch 26/30
404/404 [==============================] - 3s 7ms/step - loss: 260.5856
Epoch 27/30
404/404 [==============================] - 4s 10ms/step - loss: 127.6939
Epoch 28/30
404/404 [==============================] - 3s 8ms/step - loss: 258.7856
Epoch 29/30
404/404 [==============================] - 3s 7ms/step - loss: 254.3932
Epoch 30/30
404/404 [==============================] - 3s 8ms/step - loss: 183.3474
<keras.src.callbacks.History at 0x7eb2d36d48e0>


//testing

IN[]:
import numpy as np
#features = [Open, High, Low, Adj Close, Volume]
features = np.array([[401.970001, 427.700012, 398.200012, 20047500]])
model.predict(features)

OUT[]:
1/1 [==============================] - 1s 1s/step
array([[-0.06003069]], dtype=float32)
